{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64e6c3d-3677-43d3-aa1d-95c5d0dbda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Necessary Imports ---- \n",
    "import operator\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.graph import StateGraph, END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304de562-ea41-49cd-a7ca-82f27d257044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Agent State ----\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str      # Original question\n",
    "    #allows automatic accumulation of steps during LangGraph execution.\n",
    "    intermediate_steps: Annotated[List[str], operator.add]  # Execution logs\n",
    "    response: str    # Final answer\n",
    "    search_query: str  # Generated search terms\n",
    "    search_results: str   # Web search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80baa14-cd4c-4ef8-880e-07eb44a10580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----  Model Search and tool ----\n",
    "llm = OllamaLLM(base_url=\"http://localhost:11434\", model=\"llama3.2:1b\" )\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0b587c-fbfe-43d4-acea-9623fad11539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Logging helper-----------\n",
    "\n",
    "def log_step(state: AgentState, message: str) -> AgentState:\n",
    "    steps = state.get(\"intermediate_steps\", [])\n",
    "    if message not in steps:  # Prevent any duplicate, not just consecutive ones\n",
    "        print(f\"[STEP] {message}\")\n",
    "        return {**state, \"intermediate_steps\": steps + [message]}\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a159a5a-0e85-4b4e-ae64-7a636256fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plan Step ----\n",
    "\n",
    "def plan_search(state: AgentState):\n",
    "    if state.get(\"search_query\"):\n",
    "        return state\n",
    "\n",
    "    state = log_step(state, \"Planning search query\")\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a web based AI agent. Your job is to extract a clear, specific, and Google-searchable query \"\n",
    "        f\"from the following question:\\n\\n\"\n",
    "        f\"\\\"{state['input']}\\\"\\n\\n\"\n",
    "        \"Generate ONE well-formed search query. Avoid explanations or punctuation. Include keywords of different types if u find relevant. \"\n",
    "        \"Output only the search query, no quotes or extra text.\"\n",
    "        \"Analyze the user question,If not needed to search then you can use your own knowledge to answer \"\n",
    "    )\n",
    "    raw_query = llm.invoke(prompt).strip().split('\\n')[0]\n",
    "    query = raw_query.replace('\"', '').strip()\n",
    "\n",
    "    # Optionally log if the query is suspicious\n",
    "    if len(query.split()) < 2 or not query[0].isalnum():\n",
    "        state = log_step(state, f\"Warning: Low-confidence search query generated: '{query}'\")\n",
    "\n",
    "    state = log_step(state, f\"Generated search query: {query}\")\n",
    "    return {**state, \"search_query\": query}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b6d530-ba9d-43ca-ab6d-ce7f0542fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Node: Execute search --------\n",
    "def execute_search(state: AgentState):\n",
    "    state = log_step(state, \"Executing web search\")\n",
    "    query = state.get(\"search_query\", \"\").strip()\n",
    "    if not query:\n",
    "        state = log_step(state, \"No search query found. Skipping search.\")\n",
    "        return {**state, \"search_results\": \"\"}\n",
    "    try:\n",
    "        results = search_tool.run(query)\n",
    "        state = log_step(state, f\"Obtained search results (truncated): {results[:200]}...\")\n",
    "        return {**state, \"search_results\": results}\n",
    "    except Exception as e:\n",
    "        state = log_step(state, f\"Search failed: {str(e)}\")\n",
    "        return {**state, \"search_results\": \"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4076c5b6-1080-4c75-b825-441eeda37542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Node: Generate final answer  -----\n",
    "def generate_answer(state: AgentState):\n",
    "    state = log_step(state, \"Synthesizing final answer\")\n",
    "    prompt = (\n",
    "        f\"Based on these search results, answer the question: {state['input']}\\n\\n\"\n",
    "        f\"{state.get('search_results', '')}\"\n",
    "    )\n",
    "    answer = llm.invoke(prompt).strip()\n",
    "    state = log_step(state, \"Final answer generated.\")\n",
    "    return {**state, \"response\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ad6ea6f-62ed-4ade-b842-a2fd76aee5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Build the LangGraph workflow -----\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"plan\", plan_search)\n",
    "workflow.add_node(\"search\", execute_search)\n",
    "workflow.add_node(\"answer\", generate_answer)\n",
    "\n",
    "workflow.set_entry_point(\"plan\")\n",
    "workflow.add_edge(\"plan\", \"search\")\n",
    "workflow.add_edge(\"search\", \"answer\")\n",
    "workflow.add_edge(\"answer\", END)\n",
    "\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f398837-55e1-4935-b9a4-bc14fe7ff1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12016\\2424821238.py:36: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"🧠 Chat History\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7885\n",
      "* Running on public URL: https://ef563762e1f507af73.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ef563762e1f507af73.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP] Planning search query\n",
      "[STEP] Generated search query: I'm looking for a greeting\n",
      "[STEP] Executing web search\n",
      "[STEP] Obtained search results (truncated): e. Greet in a foreign language - Switch it up by greeting in a foreign language, and be classy! It is time to give the traditional greetings and conversations a rest! Instead, take a look at these ide...\n",
      "[STEP] Synthesizing final answer\n",
      "[STEP] Final answer generated.\n",
      "[STEP] Planning search query\n",
      "[STEP] Generated search query: india news\n",
      "[STEP] Executing web search\n",
      "[STEP] Obtained search results (truncated): India's foreign secretary also held a news conference and described the gun attack by \"terrorists\" in Indian-controlled Kashmir last month as the \"original escalation\". India carries out emergency rea...\n",
      "[STEP] Synthesizing final answer\n",
      "[STEP] Final answer generated.\n",
      "[STEP] Planning search query\n",
      "[STEP] Generated search query: 5 points news India today\n",
      "[STEP] Executing web search\n",
      "[STEP] Obtained search results (truncated): In the \"focused, measured, and non-escalatory\" Operation Sindoor, a retaliation to the Pakistan-sponsored Pahalgam attack that killed 26 Indians, its forces ensured the response was felt where it matt...\n",
      "[STEP] Synthesizing final answer\n",
      "[STEP] Final answer generated.\n",
      "[STEP] Planning search query\n",
      "[STEP] Generated search query: tech news latest updates\n",
      "[STEP] Executing web search\n",
      "[STEP] Obtained search results (truncated): Find latest technology news from every corner of the globe at Reuters.com, your online source for breaking international news coverage. Get the latest breaking tech news, innovations, and top stories ...\n",
      "[STEP] Synthesizing final answer\n",
      "[STEP] Final answer generated.\n"
     ]
    }
   ],
   "source": [
    "# ---- Launch Gradio UI ----\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def gradio_interface(user_input, history):\n",
    "    state = {\n",
    "        \"input\": user_input,\n",
    "        \"intermediate_steps\": [],\n",
    "        \"response\": \"\",\n",
    "        \"search_query\": \"\",\n",
    "        \"search_results\": \"\"\n",
    "    }\n",
    "\n",
    "    result = agent.invoke(state)\n",
    "\n",
    "    # Deduplicate intermediate steps\n",
    "    seen = set()\n",
    "    deduped_steps = []\n",
    "    for step in result[\"intermediate_steps\"]:\n",
    "        if step not in seen:\n",
    "            deduped_steps.append(step)\n",
    "            seen.add(step)\n",
    "\n",
    "    steps_summary = \"\\n\".join(f\"- {step}\" for step in deduped_steps)\n",
    "    full_response = result[\"response\"]\n",
    "\n",
    "    # Update chat history\n",
    "    history.append((f\"🧑‍💻 {user_input}\", f\"🤖 {full_response}\"))\n",
    "    return \"\", history, f\"**Steps Taken:**\\n{steps_summary}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# 🤖 AI Web Search Assistant\")\n",
    "        gr.Markdown(\"Ask anything and see how the AI finds the answer using live web search.\")\n",
    "\n",
    "        chatbot = gr.Chatbot(label=\"🧠 Chat History\")\n",
    "\n",
    "        with gr.Row():\n",
    "            txt = gr.Textbox(show_label=False, placeholder=\"Ask me something...\", scale=8)\n",
    "            ask_btn = gr.Button(\"🔍 Ask\", scale=1)\n",
    "\n",
    "        with gr.Accordion(\"Show Summary of Steps\", open=False):\n",
    "            steps_box = gr.Markdown(\"\")\n",
    "\n",
    "        clear_btn = gr.Button(\"🧹 Clear Chat\")\n",
    "\n",
    "        # Wire button and text submission\n",
    "        ask_btn.click(fn=gradio_interface, inputs=[txt, chatbot], outputs=[txt, chatbot, steps_box])\n",
    "        txt.submit(fn=gradio_interface, inputs=[txt, chatbot], outputs=[txt, chatbot, steps_box])\n",
    "\n",
    "        # Clear chat functionality\n",
    "        clear_btn.click(fn=lambda: (\"\", [], \"\"), inputs=[], outputs=[txt, chatbot, steps_box])\n",
    "\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f8837-7160-40c6-9e38-13edd1e15d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce85476-9a11-4930-b8db-1d530866eea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
